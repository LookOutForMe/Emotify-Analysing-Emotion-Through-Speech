# Speech Emotion Recognition using 1D CNN

<div align="center">
  <img src="https://i.postimg.cc/XqnkMYgp/Untitled.png" width="500px">
</div>

## Overview ğŸ™ï¸

Welcome to our revolutionary project on Speech Emotion Recognition (SER) leveraging the power of 1D Convolutional Neural Networks (CNNs). Using the renowned RAVDESS dataset, we've achieved a remarkable accuracy of 95.49% in decoding emotions from speech signals.

## Why SER? ğŸ¤”

SER is not just about understanding words; it's about delving into the intricacies of human emotions conveyed through speech. Our project aims to decipher the subtle nuances in vocal expressions to provide deeper insights into human sentiment.

## Dataset ğŸ“Š

We've utilized the RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset, a comprehensive collection of emotional speech recordings encompassing various emotions such as happiness, sadness, anger, and more. This rich dataset serves as the cornerstone of our model's training, enabling it to capture diverse emotional states.

## Model Architecture ğŸ—ï¸

Our model architecture is built upon a sophisticated 1D CNN framework meticulously crafted to extract high-level features from spectrograms of speech signals. Through a series of convolutional and pooling layers, our model learns to discern intricate emotional cues encoded within speech patterns.

## Training ğŸš€

Training our model involved a rigorous optimization process aimed at maximizing accuracy while preventing overfitting. With meticulous fine-tuning, we've achieved an impressive accuracy of 95.49%, setting new benchmarks in SER performance.

## Results ğŸ“ˆ

The performance of our model speaks volumes. With an accuracy of 95.49% on the validation set, it demonstrates unparalleled proficiency in recognizing emotions from speech signals.

## Future Directions ğŸš€

Our journey doesn't end here. We're committed to advancing SER research by exploring innovative techniques and architectures. From integrating multi-modal data sources to enhancing model robustness, the future holds endless possibilities for emotion recognition technology.

## Contributors ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»

- [Ariyan Shaw](https://github.com/LookOutForMe)
- [Kaustav Ray](https://github.com/kaustav4646)
- Ayush Kumar Chourasia
- Sneha Pal

## Connect with Us ğŸŒ

Stay updated with our latest developments.

## License ğŸ“œ

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
